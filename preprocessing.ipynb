{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter Notebook contains code to convert .tsf files to .npz files and load them.\n",
    " \n",
    "The main steps are:\n",
    "1. Import necessary libraries and define the `convert_tsf_to_dataframe` function to read and convert .tsf files into pandas DataFrames.\n",
    "2. Define a dictionary `files` that maps file numbers to their respective .tsf file names.\n",
    "3. Define the `standardize_series` function to standardize the time series data.\n",
    "4. Define the `process_and_save_tsf` function to process the .tsf files, standardize the series, and save them as .npz files.\n",
    "5. Iterate over the `files` dictionary, process each .tsf file, and save the output as .npz files.\n",
    "6. Define the `load_npz` function to load and print the contents of a .npz file.\n",
    "7. Load and print the contents of the 'weather_dataset.npz' file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from distutils.util import strtobool\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def convert_tsf_to_dataframe(\n",
    "    full_file_path_and_name,\n",
    "    replace_missing_vals_with=\"NaN\",\n",
    "    value_column_name=\"series_value\",\n",
    "):\n",
    "    col_names = []\n",
    "    col_types = []\n",
    "    all_data = {}\n",
    "    line_count = 0\n",
    "    frequency = None\n",
    "    forecast_horizon = None\n",
    "    contain_missing_values = None\n",
    "    contain_equal_length = None\n",
    "    found_data_tag = False\n",
    "    found_data_section = False\n",
    "    started_reading_data_section = False\n",
    "\n",
    "    with open(full_file_path_and_name, \"r\", encoding=\"cp1252\") as file:\n",
    "        for line in file:\n",
    "            # Strip white space from start/end of line\n",
    "            line = line.strip()\n",
    "\n",
    "            if line:\n",
    "                if line.startswith(\"@\"):  # Read meta-data\n",
    "                    if not line.startswith(\"@data\"):\n",
    "                        line_content = line.split(\" \")\n",
    "                        if line.startswith(\"@attribute\"):\n",
    "                            if (\n",
    "                                len(line_content) != 3\n",
    "                            ):  # Attributes have both name and type\n",
    "                                raise Exception(\"Invalid meta-data specification.\")\n",
    "\n",
    "                            col_names.append(line_content[1])\n",
    "                            col_types.append(line_content[2])\n",
    "                        else:\n",
    "                            if (\n",
    "                                len(line_content) != 2\n",
    "                            ):  # Other meta-data have only values\n",
    "                                raise Exception(\"Invalid meta-data specification.\")\n",
    "\n",
    "                            if line.startswith(\"@frequency\"):\n",
    "                                frequency = line_content[1]\n",
    "                            elif line.startswith(\"@horizon\"):\n",
    "                                forecast_horizon = int(line_content[1])\n",
    "                            elif line.startswith(\"@missing\"):\n",
    "                                contain_missing_values = bool(\n",
    "                                    strtobool(line_content[1])\n",
    "                                )\n",
    "                            elif line.startswith(\"@equallength\"):\n",
    "                                contain_equal_length = bool(strtobool(line_content[1]))\n",
    "\n",
    "                    else:\n",
    "                        if len(col_names) == 0:\n",
    "                            raise Exception(\n",
    "                                \"Missing attribute section. Attribute section must come before data.\"\n",
    "                            )\n",
    "\n",
    "                        found_data_tag = True\n",
    "                elif not line.startswith(\"#\"):\n",
    "                    if len(col_names) == 0:\n",
    "                        raise Exception(\n",
    "                            \"Missing attribute section. Attribute section must come before data.\"\n",
    "                        )\n",
    "                    elif not found_data_tag:\n",
    "                        raise Exception(\"Missing @data tag.\")\n",
    "                    else:\n",
    "                        if not started_reading_data_section:\n",
    "                            started_reading_data_section = True\n",
    "                            found_data_section = True\n",
    "                            all_series = []\n",
    "\n",
    "                            for col in col_names:\n",
    "                                all_data[col] = []\n",
    "\n",
    "                        full_info = line.split(\":\")\n",
    "\n",
    "                        if len(full_info) != (len(col_names) + 1):\n",
    "                            raise Exception(\"Missing attributes/values in series.\")\n",
    "\n",
    "                        series = full_info[len(full_info) - 1]\n",
    "                        series = series.split(\",\")\n",
    "\n",
    "                        if len(series) == 0:\n",
    "                            raise Exception(\n",
    "                                \"A given series should contains a set of comma separated numeric values. At least one numeric value should be there in a series. Missing values should be indicated with ? symbol\"\n",
    "                            )\n",
    "\n",
    "                        numeric_series = []\n",
    "\n",
    "                        for val in series:\n",
    "                            if val == \"?\":\n",
    "                                numeric_series.append(replace_missing_vals_with)\n",
    "                            else:\n",
    "                                numeric_series.append(float(val))\n",
    "\n",
    "                        if numeric_series.count(replace_missing_vals_with) == len(\n",
    "                            numeric_series\n",
    "                        ):\n",
    "                            raise Exception(\n",
    "                                \"All series values are missing. A given series should contains a set of comma separated numeric values. At least one numeric value should be there in a series.\"\n",
    "                            )\n",
    "\n",
    "                        all_series.append(pd.Series(numeric_series).array)\n",
    "\n",
    "                        for i in range(len(col_names)):\n",
    "                            att_val = None\n",
    "                            if col_types[i] == \"numeric\":\n",
    "                                att_val = int(full_info[i])\n",
    "                            elif col_types[i] == \"string\":\n",
    "                                att_val = str(full_info[i])\n",
    "                            elif col_types[i] == \"date\":\n",
    "                                att_val = datetime.strptime(\n",
    "                                    full_info[i], \"%Y-%m-%d %H-%M-%S\"\n",
    "                                )\n",
    "                            else:\n",
    "                                raise Exception(\n",
    "                                    \"Invalid attribute type.\"\n",
    "                                )  # Currently, the code supports only numeric, string and date types. Extend this as required.\n",
    "\n",
    "                            if att_val is None:\n",
    "                                raise Exception(\"Invalid attribute value.\")\n",
    "                            else:\n",
    "                                all_data[col_names[i]].append(att_val)\n",
    "\n",
    "                line_count = line_count + 1\n",
    "\n",
    "        if line_count == 0:\n",
    "            raise Exception(\"Empty file.\")\n",
    "        if len(col_names) == 0:\n",
    "            raise Exception(\"Missing attribute section.\")\n",
    "        if not found_data_section:\n",
    "            raise Exception(\"Missing series information under data section.\")\n",
    "\n",
    "        all_data[value_column_name] = all_series\n",
    "        loaded_data = pd.DataFrame(all_data)\n",
    "            \n",
    "        return (\n",
    "            loaded_data,\n",
    "            frequency,\n",
    "            forecast_horizon,\n",
    "            contain_missing_values,\n",
    "            contain_equal_length,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {\n",
    "    \"1\": \"bitcoin_dataset_without_missing_values.tsf\",\n",
    "    \"2\": \"covid_deaths_dataset.tsf\",\n",
    "    \"3\": \"electricity_hourly_dataset.tsf\",\n",
    "    \"4\": \"electricity_weekly_dataset.tsf\",\n",
    "    \"5\": \"fred_md_dataset.tsf\",\n",
    "    \"6\": \"hospital_dataset.tsf\",\n",
    "    \"7\": \"kaggle_web_traffic_dataset_without_missing_values.tsf\",\n",
    "    \"8\": \"kdd_cup_2018_dataset_without_missing_values.tsf\",\n",
    "    \"9\": \"london_smart_meters_dataset_without_missing_values.tsf\",\n",
    "    \"10\": \"nn5_daily_dataset_without_missing_values.tsf\",\n",
    "    \"11\": \"oikolab_weather_dataset.tsf\",\n",
    "    \"12\": \"pedestrian_counts_dataset.tsf\",\n",
    "    \"13\": \"rideshare_dataset_without_missing_values.tsf\",\n",
    "    \"14\": \"temperature_rain_dataset_without_missing_values.tsf\",\n",
    "    \"15\": \"traffic_hourly_dataset.tsf\",\n",
    "    \"16\": \"traffic_weekly_dataset.tsf\",\n",
    "    \"17\": \"weather_dataset.tsf\",\n",
    "    \"18\": \"wind_farms_minutely_dataset_without_missing_values.tsf\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_series(data):\n",
    "    return (data - np.mean(data)) / (np.std(data, ddof=0) + 1e-7)\n",
    "\n",
    "def process_and_save_tsf(file_path, output_path):\n",
    "    df, frequency, forecast_horizon, contain_missing_values, contain_equal_length = convert_tsf_to_dataframe(\n",
    "        file_path, replace_missing_vals_with=\"NaN\", value_column_name=\"series_value\"\n",
    "    )\n",
    "\n",
    "    df['series_value'] = df['series_value'].apply(standardize_series)\n",
    "    \n",
    "    npz_dict = {}\n",
    "    for index, row in df.iterrows():\n",
    "        npz_dict[row['series_name']] = row['series_value']\n",
    "    np.savez(output_path, **npz_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_number, file_name in files.items():\n",
    "    file_path = f'YOUR/SOURCE/DATASETS/{file_name}'\n",
    "    output_path = f'YOUR/TARGET/DATASETS/{file_name.replace(\".tsf\", \".npz\")}'\n",
    "    process_and_save_tsf(file_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_npz(file_path):\n",
    "    with np.load(file_path) as data:\n",
    "        print(\"Available arrays:\", list(data.keys()))\n",
    "        for key in data.keys():\n",
    "            array = data[key]\n",
    "            print(f\"{key}: {array}\")\n",
    "\n",
    "file_path = 'weather_dataset.npz'\n",
    "load_npz(file_path['T1'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_zz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
